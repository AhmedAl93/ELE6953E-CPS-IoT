{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\"text/javascript\", \"\"\"MathJax.Hub.Config({TeX: { equationNumbers: { autoNumber: \"AMS\" } }});\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LightGraphs, GraphPlot, SimpleWeightedGraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "plotlyjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consensus Protocols in Decentralized Systems\n",
    "\n",
    "## A Motivating Example: Distributed Linear Least Squares\n",
    "Consider $n$ agents, denoted by their index in the set $\\{1, \\ldots, n\\}$. Suppose that they collectively want to estimate a parameter $\\theta \\in \\mathbb R^m$ in their environment. Each node makes a linear measurement of the parameter, of the form\n",
    "$$\n",
    "y_i = C_i \\theta + v_i\n",
    "$$\n",
    "with $C_i$ a matrix associated to agent $i$ and $v_i$ some zero-mean Gaussian noise with (positive-definite) covariance matrix $\\Sigma_i$. All the noise vectors $v_i$ are independent. We assume that the matrix $C = [C_1;\\ldots;C_m]$ (Matlab notation) formed by vertically stacking the $C_i$ matrices is full column rank (this requires enough non-redundant measurements). The estimator of $\\hat \\theta$ of $\\theta$ that minimizes the mean-squared error for this Gaussian measurement case (and also the maximum likelihood estimator) is the following weighted least-squares estimate\n",
    "\\begin{equation} \\label{eq: WLLS problem}\n",
    "\\hat \\theta \\in \\arg \\min_\\theta \\; f(\\theta) := \\frac{1}{2} \\sum_{i=1}^n (y_i - C_i \\theta)^T \\Sigma_i^{-1} (y_i - C_i \\theta)\n",
    "\\end{equation}\n",
    "The weighting by $\\Sigma_i^{-1}$ gives less importance to measurements that are noisier. The solution to this quadratic optimization problem can be expressed analytically as\n",
    "$$\n",
    "\\hat \\theta = \\left( \\frac{1}{n} \\sum_{i=1}^n C_i^T \\Sigma_i^{-1} C_i \\right)^{-1} \\left( \\frac{1}{n} \\sum_{i=1}^n C_i^T \\Sigma_i^{-1} y_i\\right),\n",
    "$$\n",
    "i.e., as the ratio of two quantities averaged over the sensing nodes. One way for each node in a network to compute $\\theta$ is for the nodes to computed these two averages. The non-trivial constraint is that this must be done in a distributed manner, i.e., with each node communicating only with its neighbors. Note that node $i$ knows $C_i$, $\\Sigma_i$ and $y_i$.\n",
    "\n",
    "### A distributed optimization point-of-view\n",
    "The problem $\\eqref{eq: WLLS problem}$ can also be viewed as an example of an optimization problem to be solved in a distributed way. There are various flavors of such problems, and many distributed optimization methods have been developed. In some cases for example, the vector to optimize can be partitioned into groups of variables, one group per agent, and distributed optimization algorithms can be designed using so-called primal-dual methods in optimization. In the problem above however, there is a common variable $\\theta$ shared between the nodes, that they should agree on. In a centralized system, we could consider running a simple (but inefficient) steepest descent procedure to find the optimum $\\theta$ asymptotically, via the iterations\n",
    "$$\n",
    "\\theta_{k+1} = \\theta_k - \\alpha_k \\partial f(\\theta_k) / \\partial \\theta,\n",
    "$$\n",
    "starting from some initial estimate, e.g., $\\theta_0 = 0$, with $\\alpha_k$ some stepsizes that must satisfy certain conditions to achieve convergence. Note that here the gradient of $f$ can be written\n",
    "$$\n",
    "\\partial f / \\partial \\theta = \\sum_{i=1}^n C_i^T \\Sigma_i^{-1} C_i \\theta - C_i^T \\Sigma_i^{-1} y_i.\n",
    "$$\n",
    "So the agents could start from some common value $\\theta_0$. Then, by inducation, suppose they agree at period $k$ on the current iterate $\\theta_k$ and on the stepsize $\\alpha_k$. They could compute the gradient above by some distributed algorithm to compute the sum (or the average again, which is just the gradient scaled by $1/n$ and hence still a gradient direction). Finally after some rounds of this gradient computation scheme they could implement the gradient descent step synchronously to obtain $\\theta_{k+1}$.\n",
    "\n",
    "Yet another approach to design a distributed algorithm for this problem is to consider it as an instance of a constrained optimization problem of the type\n",
    "\\begin{align*}\n",
    "\\min_{\\theta_1, \\ldots, \\theta_n} & \\sum_{i=1}^n f_i (\\theta_i) \\\\\n",
    "\\text{s.t. } & \\theta_1 = \\theta_2 = \\ldots = \\theta_n.\n",
    "\\end{align*}\n",
    "Using this trick of adding variables $\\theta_i$, the objective completely decouples so that each agent can run a an optimization routine locally (e.g., of a gradient descent type). Then after each agent converges, they run a consensus (averaging) scheme to enfore the equality constraints, and repeat the procedure. With some effort, one can make such a scheme work, with theoretical guarantees as well.\n",
    "\n",
    "We will cover in this class some examples of such distributed optimization algorithms more formally.\n",
    "\n",
    "In the end, we emphasize the following points:\n",
    "- There are a priori many ways of designing distributed schemes to solve a give problems, such as computing an optimum solution of $\\eqref{eq: WLLS problem}$ (in fact, there are many known ways of computing such an optimum solution even in the centralized case). Different methods can achieve different trade-offs, in terms of implementation algorithmic simplicity, efficiency, convergence speed and performance, etc.\n",
    "- The problem of computing an average of quantities held at different nodes in a network, and to do so in a simple, decentralized way, arises in a surprisingly large number of problems. But even for this basic task, many variations exist, and many scenarios can be considered, e.g., on the topology of the network, the presence of directional links, the quality of the communication over these links, etc. \n",
    "\n",
    "We start our discussion with examples of distributed consensus algorithms, in the simplest setting mostly: undirected, time-invariant connectivity graphs. In the discussion, we do not attempt to provide the most general results, but instead to illustrate the basic ideas in a relatively simple setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Iterations Achieving Consensus and Average Consensus\n",
    "\n",
    "We are interested in understanding the asymptotic behavior of the following iterations\n",
    "$$\n",
    "x_{k+1} = W x_k,\n",
    "$$\n",
    "starting from some initial condition $x_0 \\in \\mathbb R^n$, for some matrix $n \\times n$ matrix $W$ with nonnegative coefficients. The matrix $W$ can be naturally associated to a digraph $G_W$, for which it represents the weight matrix. Concretely, the situation models a network of $n$ nodes as explained above. Node $i$ initially knows its initial value $x_{0,i}$. At each period $k \\geq 0$, it has in memory its current value $x_{k,i}$ and simply computes a linear combination of this value and that of its neighbors\n",
    "$$\n",
    "x_{i,k+1} = w_{ii} x_{i,k} + \\sum_{j \\in N(i)} w_{ij} x_{j,k}.\n",
    "$$\n",
    "Note in particular that in this case the directed graph $G$ will typically have self-loops, with weights $w_{ii}$, since it is natural for a node to keep a memory of its previous value when forming the linear combination. Two basic questions arise:\n",
    "- When do we have convergence to a consensus, i.e., $x_k \\to w \\mathbf{1}_n$ as $k \\to \\infty$, with $w \\in \\mathbb R$? Consensus means all nodes asymptotically agree on a common value $w$.\n",
    "- When does this value equal the average of initial values, i.e., $w = \\frac{1}{n} x_0^T \\mathbf{1}_n = \\frac{1}{n}\\sum_{i=1}^n x_{i,0}$?\n",
    "\n",
    "**Example** (successive averaging): A basic example of such an iterative scheme is obtained by having each node in an undirected graph average its own value and that of its neighbors, with equal weights. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Graph(4)\n",
    "add_edge!(network, 1, 2)\n",
    "add_edge!(network, 2, 3)\n",
    "add_edge!(network, 3, 4)\n",
    "add_edge!(network, 2, 4)\n",
    "A = adjacency_matrix(network)\n",
    "# Averaging matrix with equal weights for this undirected graph\n",
    "W = inv((eye(A)+diagm(A*ones(size(A,1))))) * (A+eye(A))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nSteps = 100\n",
    "xTraj = zeros(4,nSteps)\n",
    "xTraj[:,1] = [1; 3; 2; 2]\n",
    "for k=1:nSteps-1\n",
    "    xTraj[:,k+1] = W * xTraj[:,k]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(xTraj[:,nSteps])\n",
    "println(mean(xTraj[:,1]))\n",
    "plot(xTraj'[1:15,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the agents achieve consensus, but not to the average value. To predict the asymptotic consensus value, we can compute the dominant left eigenvector of $W$ (associated to the eigenvalue $1$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigvals(W')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = eigfact(W')\n",
    "println(F[:values][3])\n",
    "w = F[:vectors][:,3]\n",
    "w = w/sum(w)  # need the unit-norm version of the left dominant eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w'*xTraj[:,1]  # convergence toward this value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** (Metropolis-Hastings weights): As before, we start with an undirected unweighted graph $G = (V,E)$. However, we now set the weights $w_{ij} = 1/(1+\\max(d_i,d_j))$ when $i \\neq j$, $\\{i,j\\} \\in E$, and we set the weights on the diagonal in order to obtain a stochastic matrix, i.e., $w_{ii} = 1-\\sum_{\\{i,h\\} \\in E} w_{ih}$. The other weights are $0$. It is not hard to show that in this case, the weight matrix of the digraph is doubly stochastic. Moreover, we have a self-loop at each node in the digraph. The digraph is strongly connected and aperiodic, so the weight matrix is primitive. The iterations achieve consensus on the average in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function metropolisHastingsWeights(A)  # A is the adjacency matrix of an undirected graph, so symmetric\n",
    "    n = size(A,1)\n",
    "    d = A*ones(n)  # degree vector \n",
    "    Wm = zeros(Float64,size(A))\n",
    "    for i = 1:n, j = 1:n\n",
    "        Wm[i,j] = A[i,j]/(1+max(d[i],d[j]))\n",
    "    end\n",
    "    for i=1:n\n",
    "       Wm[i,i] = 1-(Wm[i,:]'*ones(n)-Wm[i,i])\n",
    "    end\n",
    "    return Wm\n",
    "end\n",
    "\n",
    "metropolisHastingsWeights(g::LightGraphs.SimpleGraphs.SimpleGraph) = metropolisHastingsWeights(adjacency_matrix(g))\n",
    "\n",
    "#Wm = metropolisHastingsWeights(A)\n",
    "Wm = metropolisHastingsWeights(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTraj_bis = zeros(4,nSteps)\n",
    "xTraj_bis[:,1] = [1; 3; 2; 2]\n",
    "for k=1:nSteps-1\n",
    "    xTraj_bis[:,k+1] = Wm * xTraj_bis[:,k]\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see that we now achieve consensus on the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(xTraj_bis[:,nSteps])\n",
    "println(mean(xTraj_bis[:,1]))\n",
    "plot(xTraj_bis'[1:15,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note however that the convergence is now slower. In general, the problem of designing the best weights to achieve average consensus as fast as possible is of interest. Some techniques for this exist, based on semi-definite programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplacian Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random undirected graph with 20 nodes, each with 3 neighbors\n",
    "srand(12345);\n",
    "n = 20;\n",
    "g1 = watts_strogatz(n, 5, 0.5)\n",
    "gplot(g1,nodelabel=1:nv(g1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = laplacian_matrix(g1);\n",
    "Matrix(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial condition for each node\n",
    "nsteps = 400\n",
    "xTraj = zeros(n,nsteps)\n",
    "xTraj[:,1] = 0.1+rand(n)\n",
    "println(\"Desired average value: $(mean(xTraj[:,1]))\")\n",
    "δt = 0.01\n",
    "for k=1:nsteps-1\n",
    "    xTraj[:,k+1] = xTraj[:,k] - δt * L * xTraj[:,k]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#λ₂ = (sort(eigvals(Matrix(L))))[2]\n",
    "λ₂ = (sort(laplacian_spectrum(g1)))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xTraj')  # plot state trajectories for the n agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem set-up - Define each agent's cost function\n",
    "nagents = 10\n",
    "preferedValues = randn(nagents)\n",
    "agentParameters = rand(nagents)\n",
    "# quadratic functions for simplicity\n",
    "individualFunction(x, prefValue, agentParam) = agentParam * (prefValue - x)^2;\n",
    "individualFunctiongradient(x, prefValue, agentParam) = 2 * agentParam * (x - prefValue);\n",
    "function totalObjective(x,prefValues,agentParams) \n",
    "    v = individualFunction(x, prefValues[1], agentParams[1])\n",
    "    for i = 2:length(prefValues)\n",
    "        v = v + individualFunction(x, prefValues[i], agentParams[i])\n",
    "    end\n",
    "    return v\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first compute the optimum value of the common variable, using a centralized method. The problem is convex, so we can use a convex programming solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pgk.add(\"Convex\")\n",
    "# Pkg.checkout(\"Convex\")\n",
    "using Convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable()\n",
    "#obj = individualFunction(x, preferedValues[1], agentParameters[1])\n",
    "#for i=2:nagents\n",
    "#    obj = obj + individualFunction(x, preferedValues[i], agentParameters[i])\n",
    "#end\n",
    "obj = totalObjective(x, preferedValues, agentParameters)\n",
    "problem = minimize(obj);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solve!(problem);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent + average consensus (primal only method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider a decentralized algorithm. We start by defining the connectivity structure between the node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network1 = watts_strogatz(nagents, 4, 0.5)\n",
    "gplot(network1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 5000\n",
    "xTraj = zeros(nagents,nsteps);\n",
    "# set the link weights for the consensus part\n",
    "W_mh = metropolisHastingsWeights(network1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTraj[:,1] = preferedValues; # every agent starts with its prefered value\n",
    "# stepsize for subgradient descent part - analysis shows it needs to be quite small\n",
    "α_step = 1e-3 * ones(nsteps) \n",
    "#α_step = 1e-1 ./ cumsum(ones(nsteps))   \n",
    "for k=1:nsteps-1\n",
    "    # compute the subgradients at the current iterate \n",
    "    d = zeros(nagents)\n",
    "    for i=1:nagents\n",
    "       d[i] = individualFunctiongradient(xTraj[i,k], preferedValues[i], agentParameters[i])\n",
    "    end\n",
    "    xTraj[:,k+1] = W_mh * xTraj[:,k] - α_step[k] * d\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xTraj'[1:100,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xTraj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalObjective(mean(xTraj[1,1:end]),preferedValues,agentParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalObjective(x.value,preferedValues,agentParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldisagreement = maximum(xTraj[:,end])-minimum(xTraj[:,end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saddle-point dynamics (primal-dual method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = adjacency_matrix(network1)\n",
    "L = diagm(W1*ones(nagents)) - W1\n",
    "#L = diagm(W_mh*ones(nagents)) - W_mh  # Laplacian matrix for the weighted graph - try this, not as good, much slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "δt = 1e-1\n",
    "nsteps = 100\n",
    "xTraj = zeros(nagents,nsteps)\n",
    "μTraj = zeros(nagents,nsteps)\n",
    "xTraj[:,1] = preferedValues\n",
    "for k=1:nsteps-1\n",
    "    d = zeros(nagents)\n",
    "    for i=1:nagents\n",
    "       d[i] = individualFunctiongradient(xTraj[i,k], preferedValues[i], agentParameters[i])\n",
    "    end\n",
    "    xTraj[:,k+1] = xTraj[:,k] + δt * (- L * (xTraj[:,k] + μTraj[:,k]) - d)\n",
    "    μTraj[:,k+1] = μTraj[:,k] + δt * L * xTraj[:,k]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(xTraj')  # potentially more accurate, faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalObjective(xTraj[1,end],preferedValues,agentParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldisagreement = maximum(xTraj[:,end])-minimum(xTraj[:,end])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
